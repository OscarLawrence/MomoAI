"""
Integration patterns for momo-vector-store.

This script demonstrates:
- Integration with external embedding models
- RAG (Retrieval Augmented Generation) patterns
- Multi-agent system integration
- Real-world application architectures
"""

import asyncio
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from momo_vector_store import VectorStore


class HuggingFaceEmbeddings(Embeddings):
    """Mock HuggingFace-style embeddings for demonstration."""

    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        self.model_name = model_name
        self.dimension = 384 if "MiniLM" in model_name else 768
        print(f"ü§ó Initializing {model_name} (dimension: {self.dimension})")

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings using sentence transformers approach."""
        embeddings = []

        for text in texts:
            # Simulate transformer-based embedding
            words = text.lower().split()

            # Create embedding based on word positions and content
            embedding = []
            for i in range(self.dimension):
                value = 0.0
                for j, word in enumerate(words[:50]):  # Limit to first 50 words
                    # Simulate attention weights and word embeddings
                    word_hash = hash(word + str(i)) % 1000
                    position_weight = 1.0 / (j + 1)  # Earlier words get more weight
                    value += (word_hash / 1000.0) * position_weight

                # Normalize to [-1, 1] range
                embedding.append((value / len(words)) * 2 - 1 if words else 0.0)

            embeddings.append(embedding)

        return embeddings

    def embed_query(self, text: str) -> List[float]:
        """Generate query embedding."""
        return self.embed_documents([text])[0]


@dataclass
class SearchContext:
    """Context for contextual search operations."""

    user_id: str
    session_id: str
    search_history: List[str]
    preferences: Dict[str, Any]
    domain: str


class RAGPipeline:
    """Retrieval Augmented Generation pipeline demonstration."""

    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.generation_history = []

    async def retrieve(
        self, query: str, k: int = 5, filters: Optional[Dict] = None
    ) -> List[Document]:
        """Retrieve relevant documents for the query."""
        print(f"üîç Retrieving documents for: '{query}'")

        results = await self.vector_store.search_with_score(query, k=k, filter=filters)

        retrieved_docs = []
        for doc, score in results:
            print(f"   Retrieved (score: {score:.3f}): {doc.page_content[:50]}...")
            retrieved_docs.append(doc)

        return retrieved_docs

    def augment_prompt(self, query: str, retrieved_docs: List[Document]) -> str:
        """Augment the user query with retrieved context."""
        context_texts = []

        for i, doc in enumerate(retrieved_docs, 1):
            metadata_str = ", ".join([f"{k}: {v}" for k, v in doc.metadata.items()])
            context_texts.append(f"Document {i}: {doc.page_content}")
            context_texts.append(f"Metadata: {metadata_str}")

        context = "\n\n".join(context_texts)

        augmented_prompt = f"""
Context Information:
{context}

User Question: {query}

Based on the context information above, please provide a comprehensive answer to the user's question. 
If the context doesn't contain relevant information, please indicate that.
"""

        return augmented_prompt

    def generate_response(self, augmented_prompt: str) -> str:
        """Simulate language model response generation."""
        print("ü§ñ Generating response with retrieved context...")

        # This would typically call an actual LLM like GPT, Claude, etc.
        # For demo purposes, we'll create a simple response
        response = """
Based on the retrieved documents, I can provide you with relevant information about your query. 
The retrieved context shows multiple perspectives and technical details that help form a comprehensive answer.

Key points from the retrieved information:
- The documents provide specific technical details and implementation guidance
- Multiple sources confirm the main concepts and approaches
- The metadata indicates these are authoritative sources on the topic

[This is a simulated response - in a real RAG system, this would be generated by an LLM]
"""

        self.generation_history.append(
            {"prompt": augmented_prompt, "response": response}
        )

        return response

    async def rag_query(
        self, query: str, k: int = 5, filters: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Complete RAG pipeline: retrieve, augment, generate."""
        retrieved_docs = await self.retrieve(query, k, filters)
        augmented_prompt = self.augment_prompt(query, retrieved_docs)
        response = self.generate_response(augmented_prompt)

        return {
            "query": query,
            "retrieved_docs": len(retrieved_docs),
            "response": response,
            "sources": [
                doc.metadata.get("source", "unknown") for doc in retrieved_docs
            ],
        }


class MultiAgentVectorStore:
    """Multi-agent system integration with vector store."""

    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.agent_contexts = {}

    async def register_agent(
        self, agent_id: str, agent_type: str, capabilities: List[str]
    ):
        """Register an agent and its capabilities in the vector store."""
        agent_doc = Document(
            page_content=f"Agent {agent_id} is a {agent_type} agent with capabilities: {', '.join(capabilities)}. "
            f"This agent can handle tasks related to these domains and provide specialized assistance.",
            metadata={
                "type": "agent",
                "agent_id": agent_id,
                "agent_type": agent_type,
                "capabilities": capabilities,
                "status": "active",
            },
        )

        await self.vector_store.add_documents([agent_doc])
        print(
            f"ü§ñ Registered agent {agent_id} ({agent_type}) with capabilities: {capabilities}"
        )

    async def find_suitable_agents(
        self, task_description: str, k: int = 3
    ) -> List[Document]:
        """Find agents suitable for a given task."""
        print(f"üîç Finding agents for task: '{task_description}'")

        results = await self.vector_store.search(
            task_description, k=k, filter={"type": "agent", "status": "active"}
        )

        suitable_agents = []
        for doc in results:
            agent_id = doc.metadata.get("agent_id")
            agent_type = doc.metadata.get("agent_type")
            capabilities = doc.metadata.get("capabilities", [])
            print(f"   Found: {agent_id} ({agent_type}) - {capabilities}")
            suitable_agents.append(doc)

        return suitable_agents

    async def delegate_task(
        self, task: str, preferred_agent_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """Delegate a task to the most suitable agent."""
        filters = {"type": "agent", "status": "active"}
        if preferred_agent_type:
            filters["agent_type"] = preferred_agent_type

        agents = await self.vector_store.search(task, k=1, filter=filters)

        if agents:
            chosen_agent = agents[0]
            agent_id = chosen_agent.metadata.get("agent_id")

            # Simulate task execution
            result = {
                "task": task,
                "assigned_agent": agent_id,
                "agent_type": chosen_agent.metadata.get("agent_type"),
                "status": "completed",
                "result": f"Task '{task}' completed by agent {agent_id}",
            }

            print(f"‚úÖ Task delegated to {agent_id}: {task}")
            return result
        else:
            print(f"‚ùå No suitable agent found for task: {task}")
            return {"task": task, "status": "no_agent_available"}


class ContextualSearchSystem:
    """Contextual search system that maintains user context."""

    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.user_contexts = {}

    def update_context(self, context: SearchContext):
        """Update user search context."""
        self.user_contexts[context.user_id] = context
        print(
            f"üìù Updated context for user {context.user_id} in domain '{context.domain}'"
        )

    async def contextual_search(
        self, user_id: str, query: str, k: int = 5
    ) -> List[Document]:
        """Perform search with user context consideration."""
        context = self.user_contexts.get(user_id)

        if not context:
            print(
                f"‚ö†Ô∏è  No context found for user {user_id}, performing standard search"
            )
            return await self.vector_store.search(query, k=k)

        # Build context-aware query
        contextual_query = f"{query} {context.domain}"
        if context.search_history:
            recent_searches = " ".join(context.search_history[-3:])
            contextual_query += f" related to {recent_searches}"

        print(f"üéØ Contextual search for {user_id}: '{contextual_query}'")

        # Apply domain filter if available
        filters = {}
        if "domain" in context.preferences:
            filters["category"] = context.preferences["domain"]

        results = await self.vector_store.search(
            contextual_query, k=k, filter=filters if filters else None
        )

        # Update search history
        context.search_history.append(query)
        if len(context.search_history) > 10:
            context.search_history = context.search_history[-10:]

        return results


async def setup_knowledge_base():
    """Set up a comprehensive knowledge base for integration demos."""
    documents = [
        # Technology documentation
        Document(
            page_content="Vector databases enable semantic search by storing high-dimensional embeddings and performing similarity calculations. They're essential for AI applications like RAG systems.",
            metadata={
                "source": "tech_docs",
                "category": "database",
                "topic": "vector_search",
                "difficulty": "intermediate",
            },
        ),
        Document(
            page_content="Retrieval Augmented Generation (RAG) combines information retrieval with language generation to provide more accurate and contextual responses by grounding generation in relevant documents.",
            metadata={
                "source": "ai_research",
                "category": "ai",
                "topic": "rag",
                "difficulty": "advanced",
            },
        ),
        Document(
            page_content="Multi-agent systems coordinate multiple AI agents to solve complex problems collaboratively. Each agent has specialized capabilities and can communicate with others.",
            metadata={
                "source": "ai_research",
                "category": "ai",
                "topic": "multi_agent",
                "difficulty": "advanced",
            },
        ),
        Document(
            page_content="Embedding models convert text into numerical vectors that capture semantic meaning. Popular models include sentence-transformers and OpenAI's text-embedding models.",
            metadata={
                "source": "ml_guides",
                "category": "ai",
                "topic": "embeddings",
                "difficulty": "intermediate",
            },
        ),
        Document(
            page_content="LangChain is a framework for developing applications with large language models, providing abstractions for document loading, text splitting, and vector stores.",
            metadata={
                "source": "framework_docs",
                "category": "tools",
                "topic": "langchain",
                "difficulty": "beginner",
            },
        ),
        # Business applications
        Document(
            page_content="Customer support chatbots can be enhanced with RAG systems to provide accurate answers based on company documentation and knowledge bases.",
            metadata={
                "source": "business_cases",
                "category": "application",
                "topic": "customer_support",
                "difficulty": "beginner",
            },
        ),
        Document(
            page_content="Document analysis systems help organizations extract insights from large document collections using semantic search and automated summarization.",
            metadata={
                "source": "business_cases",
                "category": "application",
                "topic": "document_analysis",
                "difficulty": "intermediate",
            },
        ),
    ]

    return documents


async def demonstrate_rag_integration():
    """Demonstrate RAG pipeline integration."""
    print("\nüîó RAG Pipeline Integration")
    print("-" * 40)

    # Setup
    embeddings = HuggingFaceEmbeddings("sentence-transformers/all-MiniLM-L6-v2")
    store = VectorStore(backend_type="memory", embeddings=embeddings)

    documents = await setup_knowledge_base()
    await store.add_documents(documents)

    rag_pipeline = RAGPipeline(store)

    # RAG queries
    queries = [
        "How do vector databases work?",
        "What is RAG and how does it improve AI responses?",
        "How can I implement a customer support chatbot?",
    ]

    for query in queries:
        print(f"\nüìù RAG Query: '{query}'")
        result = await rag_pipeline.rag_query(query, k=3)
        print(f"   Retrieved {result['retrieved_docs']} documents")
        print(f"   Sources: {result['sources']}")
        print(f"   Response preview: {result['response'][:100]}...")


async def demonstrate_multi_agent_integration():
    """Demonstrate multi-agent system integration."""
    print("\nü§ñ Multi-Agent System Integration")
    print("-" * 40)

    embeddings = HuggingFaceEmbeddings()
    store = VectorStore(backend_type="memory", embeddings=embeddings)

    # Add knowledge base
    documents = await setup_knowledge_base()
    await store.add_documents(documents)

    multi_agent = MultiAgentVectorStore(store)

    # Register different types of agents
    await multi_agent.register_agent(
        "code_reviewer",
        "code_analysis",
        ["python", "javascript", "code_quality", "security"],
    )
    await multi_agent.register_agent(
        "doc_writer",
        "documentation",
        ["technical_writing", "api_docs", "tutorials", "markdown"],
    )
    await multi_agent.register_agent(
        "data_analyst", "analytics", ["sql", "statistics", "visualization", "reporting"]
    )
    await multi_agent.register_agent(
        "ml_specialist",
        "machine_learning",
        ["pytorch", "tensorflow", "model_training", "evaluation"],
    )

    # Demonstrate task delegation
    tasks = [
        "Review Python code for security vulnerabilities",
        "Write documentation for a REST API",
        "Analyze user behavior data and create visualizations",
        "Train a classification model on customer data",
    ]

    for task in tasks:
        result = await multi_agent.delegate_task(task)
        print(f"   Task: {task}")
        print(
            f"   Result: {result['status']} by {result.get('assigned_agent', 'none')}"
        )


async def demonstrate_contextual_search():
    """Demonstrate contextual search system."""
    print("\nüéØ Contextual Search System")
    print("-" * 40)

    embeddings = HuggingFaceEmbeddings()
    store = VectorStore(backend_type="memory", embeddings=embeddings)

    documents = await setup_knowledge_base()
    await store.add_documents(documents)

    contextual_system = ContextualSearchSystem(store)

    # Create user contexts
    ai_researcher_context = SearchContext(
        user_id="ai_researcher",
        session_id="session_001",
        search_history=["neural networks", "transformers"],
        preferences={"domain": "ai", "difficulty": "advanced"},
        domain="artificial_intelligence",
    )

    developer_context = SearchContext(
        user_id="developer",
        session_id="session_002",
        search_history=["python", "web development"],
        preferences={"domain": "tools", "difficulty": "intermediate"},
        domain="software_development",
    )

    # Update contexts
    contextual_system.update_context(ai_researcher_context)
    contextual_system.update_context(developer_context)

    # Perform contextual searches
    query = "how to build better systems"

    print(f"\nQuery: '{query}'")

    print("\n   AI Researcher perspective:")
    ai_results = await contextual_system.contextual_search("ai_researcher", query, k=3)
    for doc in ai_results:
        topic = doc.metadata.get("topic", "general")
        print(f"     - {topic}: {doc.page_content[:60]}...")

    print("\n   Developer perspective:")
    dev_results = await contextual_system.contextual_search("developer", query, k=3)
    for doc in dev_results:
        topic = doc.metadata.get("topic", "general")
        print(f"     - {topic}: {doc.page_content[:60]}...")


async def demonstrate_real_world_architecture():
    """Demonstrate a real-world application architecture."""
    print("\nüèóÔ∏è  Real-World Application Architecture")
    print("-" * 40)

    print("Architecture: Enterprise Knowledge Management System")
    print("Components:")
    print("  1. Document Ingestion Service")
    print("     - Processes PDFs, docs, web pages")
    print("     - Chunks content intelligently")
    print("     - Generates embeddings")
    print("  2. Vector Store (momo-vector-store)")
    print("     - Stores document embeddings")
    print("     - Enables semantic search")
    print("     - Supports metadata filtering")
    print("  3. RAG Pipeline")
    print("     - Retrieves relevant documents")
    print("     - Augments user queries with context")
    print("     - Generates contextual responses")
    print("  4. Multi-Agent Orchestrator")
    print("     - Routes queries to specialized agents")
    print("     - Coordinates complex workflows")
    print("     - Manages agent interactions")
    print("  5. User Interface")
    print("     - Web dashboard for search")
    print("     - API endpoints for integration")
    print("     - Real-time response streaming")

    # Simulate the architecture
    embeddings = HuggingFaceEmbeddings()

    # Production setup would use persistent storage
    print("\nProduction configuration example:")
    print("  store = VectorStore(")
    print("      backend_type='chroma',")
    print("      embeddings=embeddings,")
    print("      collection_name='enterprise_knowledge',")
    print("      persist_directory='/data/chroma',")
    print("      client_settings={'host': 'chroma.company.com'}")
    print("  )")

    # For demo, use memory backend
    store = VectorStore(backend_type="memory", embeddings=embeddings)
    documents = await setup_knowledge_base()
    await store.add_documents(documents)

    # Simulate enterprise query
    enterprise_query = "How can we implement AI-powered customer support?"
    print(f"\nEnterprise Query: '{enterprise_query}'")

    results = await store.search(
        enterprise_query, k=3, filter={"category": "application"}
    )

    print("System Response:")
    for i, doc in enumerate(results, 1):
        topic = doc.metadata.get("topic", "general")
        print(f"  {i}. [{topic}] {doc.page_content[:80]}...")


async def main():
    """Run the integration patterns demonstration."""
    print("üîó Integration Patterns for Vector Store")
    print("=" * 50)

    await demonstrate_rag_integration()
    await demonstrate_multi_agent_integration()
    await demonstrate_contextual_search()
    await demonstrate_real_world_architecture()

    print("\n‚úÖ Integration patterns demonstration completed!")
    print("\nIntegration Summary:")
    print("- RAG Pipeline: Enhances generation with retrieved context")
    print("- Multi-Agent Systems: Coordinates specialized AI agents")
    print("- Contextual Search: Personalizes results based on user context")
    print("- Enterprise Architecture: Scalable real-world deployment patterns")
    print("- Flexible Backend: Easy to switch from development to production")


if __name__ == "__main__":
    asyncio.run(main())
